{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled1.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMyucKcVpBzU+tO3IHbPP2i",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jhphan/ML-Notebooks/blob/main/tcga-scikit-learn-logistic-regression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M6BEFHj2dd5a"
      },
      "source": [
        "# authenticate to gcloud\n",
        "!gcloud auth application-default login"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "veP6gPatu2iW"
      },
      "source": [
        "# udpate these variables\n",
        "client_project = 'cgc-05-0051'\n",
        "cancer_type = 'TCGA-GBM'\n",
        "project = 'isb-cgc-bq'"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YyiPNZ4uwpwP"
      },
      "source": [
        "# Load dependencies\n",
        "from google.cloud import bigquery\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HNkfSXedwzbC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "48eb76bb-984f-40a4-fb43-8554c8f6a747"
      },
      "source": [
        "# Create a client to access the data within BigQuery\n",
        "client = bigquery.Client(client_project)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/google/auth/_default.py:70: UserWarning: Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a \"quota exceeded\" or \"API not enabled\" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/\n",
            "  warnings.warn(_CLOUD_SDK_CREDENTIALS_WARNING)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Py_JW_kXAlxX",
        "outputId": "e9610d63-2db1-453f-8936-4c3c41c0e8c2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        }
      },
      "source": [
        "# Get the list of unique proteins to create a pivot table\n",
        "demo_gender = client.query(\n",
        "  (\"\"\"\n",
        "    SELECT count(demo__gender) as number, demo__gender from `{}.TCGA.clinical_gdc_current` where proj__project_id = '{}' group by demo__gender\n",
        "  \"\"\").format(project, cancer_type)\n",
        ").result().to_dataframe()\n",
        "demo_gender"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>number</th>\n",
              "      <th>demo__gender</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>230</td>\n",
              "      <td>female</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>366</td>\n",
              "      <td>male</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>not reported</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   number  demo__gender\n",
              "0       0          None\n",
              "1     230        female\n",
              "2     366          male\n",
              "3       3  not reported"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WYKK8nT7Rzpa"
      },
      "source": [
        "# Get the list of unique proteins to create a pivot table\n",
        "protein_names = client.query(\n",
        "  (\"\"\"\n",
        "    SELECT CONCAT(\n",
        "      '(\"',\n",
        "      STRING_AGG(\n",
        "        DISTINCT CONCAT('p_', REPLACE(protein_name, \"-\", \"_\")), '\", \"'\n",
        "      ),\n",
        "      '\")'\n",
        "    ) AS protein_names \n",
        "    FROM `{}.TCGA.protein_expression_hg38_gdc_current`\n",
        "  \"\"\").format(project)\n",
        ").result().to_dataframe()['protein_names'][0]\n",
        "protein_names"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fvsIkkJ3P3r-"
      },
      "source": [
        "# Join clinical and protein expression data to create a labeled pivot table\n",
        "protein_expression = client.query(\n",
        "  (\"\"\"\n",
        "    SELECT * FROM (\n",
        "      SELECT \n",
        "        pe.case_barcode AS sample,\n",
        "        labels.survival_label AS label,\n",
        "        CONCAT('p_', REPLACE(pe.protein_name, \"-\", \"_\")) AS protein_name,\n",
        "        pe.protein_expression AS protein_expression\n",
        "      FROM `isb-cgc-bq.TCGA.protein_expression_hg38_gdc_current` AS pe\n",
        "      INNER JOIN (\n",
        "        SELECT *\n",
        "        FROM (\n",
        "          SELECT\n",
        "            submitter_id,\n",
        "            demo__vital_status,\n",
        "            demo__days_to_death,\n",
        "            diag__days_to_last_follow_up,\n",
        "            CASE\n",
        "              WHEN demo__vital_status = 'Dead' AND demo__days_to_death < 365*5 THEN 0\n",
        "              WHEN (\n",
        "                (demo__vital_status = 'Dead' AND demo__days_to_death >= 365*5)\n",
        "                OR (demo__vital_status = 'Alive' AND diag__days_to_last_follow_up >= 365*5)\n",
        "              ) THEN 1\n",
        "            END AS survival_label\n",
        "          FROM `{}.TCGA.clinical_gdc_current`\n",
        "          WHERE proj__project_id = '{}'\n",
        "        )\n",
        "        WHERE survival_label IS NOT NULL\n",
        "      ) labels\n",
        "      ON labels.submitter_id = pe.case_barcode\n",
        "    )\n",
        "    PIVOT (\n",
        "      MAX(protein_expression) FOR protein_name IN {}\n",
        "    )\n",
        "    ORDER BY sample ASC\n",
        "  \"\"\").format(project, cancer_type, protein_names)\n",
        ").result().to_dataframe()\n",
        "protein_expression"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kgN1PtBvhNpx"
      },
      "source": [
        "# find and remove samples that have no valid protein values (all missing)\n",
        "samples_notnull = protein_expression.loc[:, 'p_AR':].notnull().sum(axis=1)>0\n",
        "# find and remove proteins that have any NULL values\n",
        "proteins_notnull = pd.Series(\n",
        "  [True, True],\n",
        "  index=['sample', 'label']\n",
        ").append(\n",
        "  protein_expression.loc[:, 'p_AR':].isnull().sum(axis=0)==0\n",
        ")\n",
        "# create a new filtered DF\n",
        "protein_expression_filtered = protein_expression.loc[samples_notnull, proteins_notnull]\n",
        "protein_expression_filtered"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VF90HWh_SM5e"
      },
      "source": [
        "# remove sample names from table\n",
        "protein_expression_filtered.pop('sample')\n",
        "\n",
        "# split data into train, val, and test sets\n",
        "train_data = protein_expression_filtered.sample(frac=0.8, random_state=1)\n",
        "val_data = protein_expression_filtered.drop(train_data.index)\n",
        "test_data = val_data.sample(frac=0.5, random_state=1)\n",
        "val_data = val_data.drop(test_data.index)\n",
        "\n",
        "data = dict()\n",
        "data['train_y'] = train_data.pop('label')\n",
        "data['val_y'] = val_data.pop('label')\n",
        "data['test_y'] = test_data.pop('label')\n",
        "\n",
        "# calculate fold change and get top 20 proteins\n",
        "train_fold_change = abs(train_data.loc[data['train_y']==1, 'p_AR':].mean(axis=0) - train_data.loc[data['train_y']==0, 'p_AR':].mean(axis=0))\n",
        "top_train_fold_change = train_fold_change.sort_values(ascending=False) #.head(10)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "data['train_x'] = scaler.fit_transform(train_data.loc[:,top_train_fold_change.index])\n",
        "data['val_x'] = scaler.transform(val_data.loc[:,top_train_fold_change.index])\n",
        "data['test_x'] = scaler.transform(test_data.loc[:,top_train_fold_change.index])\n",
        "\n",
        "data['scaler'] = scaler"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RGY5mKD3ys8L"
      },
      "source": [
        "from sklearn import svm\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "clf = svm.LinearSVC(max_iter=2000)\n",
        "clf.fit(data['train_x'], data['train_y'])\n",
        "pred = clf.predict(data['val_x'])\n",
        "acc = accuracy_score(data['val_y'], pred)\n",
        "acc, clf\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jdvjdKkLzRj_"
      },
      "source": [
        "data['val_y'], pred"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yiGNmYQomI28"
      },
      "source": [
        "# build DNN model\n",
        "\n",
        "from keras.layers import Input, Dense, Dropout\n",
        "from keras.models import Model\n",
        "\n",
        "input_features = data['train_x'].shape[1]\n",
        "\n",
        "# build the network\n",
        "inputs = Input(shape=(input_features,), name='input')\n",
        "x = Dense(64, activation='relu', name='hidden1', kernel_regularizer='l2')(inputs)\n",
        "x = Dropout(0.5)(x)\n",
        "x = Dense(32, activation='relu', name='hidden2', kernel_regularizer='l2')(x)\n",
        "x = Dense(16, activation='relu', name='hidden3')(x)\n",
        "x = Dense(8, activation='relu', name='hidden4')(x)\n",
        "x = Dense(4, activation='relu', name='hidden5')(x)\n",
        "prediction = Dense(1, activation='sigmoid', name='final')(inputs)\n",
        "model = Model(inputs=inputs, outputs=prediction)\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qtpCfoWDpk4n"
      },
      "source": [
        "model.fit(x=data['train_x'], y=data['train_y'], \\\n",
        "          batch_size=32, epochs=300, verbose=1, validation_data=(data['val_x'], data['val_y']))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tOTSKzV4u4B9"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}